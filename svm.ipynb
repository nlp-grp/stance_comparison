{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78785d2-776c-4f9a-8027-11ee9d8c3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import json\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "from nltk.util import ngrams\n",
    "#from google.colab import drive\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import sparse\n",
    "import os\n",
    "import warnings\n",
    "from stance_utils import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd319a6f-820e-4225-abfa-e9ae3222c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = '/data/parush/stance_mohammed/new_train.txt'\n",
    "test_data_file = '/data/parush/stance_mohammed/new_test.txt'\n",
    "TARGETS = [ 'Atheism','Climate Change is a Real Concern', 'Feminist Movement','Hillary Clinton', 'Legalization of Abortion', 'Donald Trump']\n",
    "\n",
    "\n",
    "# train_data_file = '/data/parush/SomasundaranWiebe-politicalDebates/train.txt'\n",
    "# test_data_file = '/data/parush/SomasundaranWiebe-politicalDebates/test.txt'\n",
    "# TARGETS = ['god','healthcare','guns','gayRights','abortion', 'creation']\n",
    "\n",
    "\n",
    "# train_data_file = '/data/parush/Data_MPCHI/train.txt'\n",
    "# test_data_file = '/data/parush/Data_MPCHI/test.txt'\n",
    "# TARGETS = ['Are E-Cigarettes safe?','Does MMR Vaccine lead to autism in children?',\n",
    "#       'Does Sunlight exposure lead to skin cancer?','Does Vitamin C prevent common cold?',\n",
    "#       'Should women take HRT post-menopause?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03433752-8a67-4d07-82b2-1d6389e98b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_data_file, sep='\\t')\n",
    "df1 = pd.read_csv(test_data_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3e8a0fb-7d51-42e6-8590-47ae41baa197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Target</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Opinion towards</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>TARGET</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>Hillary is our best choice if we truly want to...</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>TARGET</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>@TheView I think our country is ready for a fe...</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>TARGET</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>TARGET</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>@PortiaABoulger Thank you for adding me to you...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NO ONE</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>20189</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Donald Trump is in dire need of a crisis commu...</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3440</th>\n",
       "      <td>20671</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>And America wants to protest a silly flag but ...</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>20421</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>@realDonaldTrump has formed the \"Racistublican...</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>20257</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>The #Obama Presidency: Has There Ever a Point ...</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>20703</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>@realDonaldTrump we all want you as the next p...</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3444 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID           Target  \\\n",
       "0         1  Hillary Clinton   \n",
       "1         2  Hillary Clinton   \n",
       "2         3  Hillary Clinton   \n",
       "3         4  Hillary Clinton   \n",
       "4         5  Hillary Clinton   \n",
       "...     ...              ...   \n",
       "3439  20189     Donald Trump   \n",
       "3440  20671     Donald Trump   \n",
       "3441  20421     Donald Trump   \n",
       "3442  20257     Donald Trump   \n",
       "3443  20703     Donald Trump   \n",
       "\n",
       "                                                  Tweet   Stance  \\\n",
       "0     @tedcruz And, #HandOverTheServer she wiped cle...  AGAINST   \n",
       "1     Hillary is our best choice if we truly want to...    FAVOR   \n",
       "2     @TheView I think our country is ready for a fe...  AGAINST   \n",
       "3     I just gave an unhealthy amount of my hard-ear...  AGAINST   \n",
       "4     @PortiaABoulger Thank you for adding me to you...     NONE   \n",
       "...                                                 ...      ...   \n",
       "3439  Donald Trump is in dire need of a crisis commu...  AGAINST   \n",
       "3440  And America wants to protest a silly flag but ...     NONE   \n",
       "3441  @realDonaldTrump has formed the \"Racistublican...  AGAINST   \n",
       "3442  The #Obama Presidency: Has There Ever a Point ...  AGAINST   \n",
       "3443  @realDonaldTrump we all want you as the next p...    FAVOR   \n",
       "\n",
       "     Opinion towards Sentiment  \n",
       "0             TARGET  NEGATIVE  \n",
       "1             TARGET  POSITIVE  \n",
       "2             TARGET  NEGATIVE  \n",
       "3             TARGET  NEGATIVE  \n",
       "4             NO ONE  POSITIVE  \n",
       "...              ...       ...  \n",
       "3439             NaN       NaN  \n",
       "3440             NaN       NaN  \n",
       "3441             NaN       NaN  \n",
       "3442             NaN       NaN  \n",
       "3443             NaN       NaN  \n",
       "\n",
       "[3444 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9192be3-17a3-4655-a43b-d65508a92ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = 'tfidf'   # set 'count' or 'tfidf'\n",
    "analyzer = 'both'  # set 'word' or 'both' ( word and char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6611b8c7-1a78-48d6-80c5-4006e7b70135",
   "metadata": {},
   "outputs": [],
   "source": [
    "if vectorizer == 'count':\n",
    "    if analyzer == 'word':\n",
    "        vectorizer = CountVectorizer(analyzer='word',ngram_range=(1,1))\n",
    "    else:\n",
    "        vectorizer = CountVectorizer(analyzer='word',ngram_range=(1,3))\n",
    "        char_vectorizer = CountVectorizer(analyzer='char',ngram_range=(2,5))\n",
    "else:\n",
    "    if analyzer == 'word':\n",
    "        vectorizer = TfidfVectorizer(analyzer='word',ngram_range=(1,1))\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(analyzer='word',ngram_range=(1,3))\n",
    "        char_vectorizer = TfidfVectorizer(analyzer='char',ngram_range=(2,5))\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c0b9dc-2961-4d7c-abef-b1287345064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of FAVOR Tweets\n",
    "def get_training_data_and_labels(file,target):\n",
    "    print(\"Working on target:\", target)\n",
    "    \n",
    "    train_corpus = []\n",
    "    train_labels = []\n",
    "    classes = {'FAVOR': 0, 'AGAINST': 1, 'NONE': 2}\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            line = line.replace('#SemST', '').strip()\n",
    "            line = line.split('\\t')\n",
    "            if line[0].strip() != 'ID' and target in line[1].strip():\n",
    "            #if line[0].strip() != 'ID':  #Uncomment this line if training on wholedataset and comment the line above.\n",
    "                \n",
    "                tweet = line[2]\n",
    "                stance = line[3]\n",
    "                \n",
    "                train_corpus.append(tweet)\n",
    "                train_labels.append(classes[stance])\n",
    "\n",
    "    \n",
    "    if analyzer == 'word':\n",
    "        ngram_vectorized_data = vectorizer.fit_transform(train_corpus)\n",
    "        \n",
    "        return ngram_vectorized_data, train_labels\n",
    "    else:\n",
    "        ngram_vectorized_data = vectorizer.fit_transform(train_corpus)\n",
    "        char_vectorized_data = char_vectorizer.fit_transform(train_corpus)\n",
    "        l = np.hstack((ngram_vectorized_data.toarray(), char_vectorized_data.toarray()))\n",
    "        train_vectorized_data = sparse.csr_matrix(l)\n",
    "        \n",
    "        return train_vectorized_data, train_labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f27958c-66b9-44b2-b560-e08546a75466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing test_data\n",
    "def get_test_data_and_labels(file,target):\n",
    "    print(\"Working on target:\", target)\n",
    "    test_corpus = []\n",
    "    test_labels = []\n",
    "    classes = {'FAVOR': 0, 'AGAINST': 1, 'NONE': 2}\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            line = line.replace('#SemST', '').strip()\n",
    "            line = line.split('\\t')\n",
    "        #if line[0].strip() != 'ID' and line[3].strip() == 'FAVOR' and line[1] == t:\n",
    "            if line[0].strip() != 'ID' and target in line[1].strip():\n",
    "            #if line[0].strip() != 'ID': #Uncomment this line if testing on wholedataset and comment the line above.\n",
    "                tweet = line[2]\n",
    "                stance = line[3]\n",
    "                #print(line[0])\n",
    "                test_corpus.append(tweet)\n",
    "                test_labels.append(classes[stance])\n",
    "    if analyzer == 'word':\n",
    "        test_ngram_vectorized_data = vectorizer.transform(test_corpus)\n",
    "        \n",
    "        return test_ngram_vectorized_data, test_labels\n",
    "    else:\n",
    "        test_ngram_vectorized_data = vectorizer.transform(test_corpus)\n",
    "        test_char_vectorized_data = char_vectorizer.transform(test_corpus)\n",
    "        l2 = np.hstack((test_ngram_vectorized_data.toarray(), test_char_vectorized_data.toarray()))\n",
    "        test_vectorized_data = sparse.csr_matrix(l2)\n",
    "        \n",
    "        \n",
    "        return test_vectorized_data,test_labels\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e031376d-4eda-4702-b808-414dbe26f13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on target: Legalization of Abortion\n",
      "Working on target: Legalization of Abortion\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train =  get_training_data_and_labels(train_data_file, TARGETS[4])\n",
    "X_test, y_test = get_test_data_and_labels(test_data_file,TARGETS[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e4c20-f40b-42ee-812d-34bce5b3aeae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206166ad-5bb2-441b-923c-8e68333be2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a366706b-ddf4-4075-bd77-c702cd02e62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4055f07-7a23-49ae-9cce-8b429516bf47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19c66d16-3c8f-467c-a1d1-e0693abdc63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e76ab165-d71e-40f0-a3ce-692dfa221cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.127 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.127 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.127 (+/-0.000) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.127 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.412 (+/-0.060) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.127 (+/-0.000) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.580 (+/-0.030) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.414 (+/-0.057) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.583 (+/-0.033) for {'C': 1, 'kernel': 'linear'}\n",
      "0.581 (+/-0.028) for {'C': 10, 'kernel': 'linear'}\n",
      "0.581 (+/-0.028) for {'C': 100, 'kernel': 'linear'}\n",
      "0.581 (+/-0.028) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6087    0.5072    0.5534       138\n",
      "           1     0.6023    0.6319    0.6168       163\n",
      "\n",
      "   micro avg     0.6049    0.5748    0.5894       301\n",
      "   macro avg     0.6055    0.5696    0.5851       301\n",
      "weighted avg     0.6053    0.5748    0.5877       301\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.333 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.333 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.333 (+/-0.000) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.333 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.396 (+/-0.013) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.333 (+/-0.000) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.559 (+/-0.016) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.398 (+/-0.016) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.562 (+/-0.018) for {'C': 1, 'kernel': 'linear'}\n",
      "0.560 (+/-0.015) for {'C': 10, 'kernel': 'linear'}\n",
      "0.560 (+/-0.015) for {'C': 100, 'kernel': 'linear'}\n",
      "0.560 (+/-0.015) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6087    0.5072    0.5534       138\n",
      "           1     0.6023    0.6319    0.6168       163\n",
      "\n",
      "   micro avg     0.6049    0.5748    0.5894       301\n",
      "   macro avg     0.6055    0.5696    0.5851       301\n",
      "weighted avg     0.6053    0.5748    0.5877       301\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}, {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "\n",
    "for score in scores:\n",
    "    \n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    cv = StratifiedKFold(n_splits=2, shuffle=True, random_state = 2 )\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score, cv = cv\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred, digits = 4,labels = [0,1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d75066a-0434-4800-9c02-e2fb50f3f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(y_true, y_pred, digits = 4,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee12ee-c29b-4a9d-86d3-ae128510511b",
   "metadata": {},
   "source": [
    "## Test on another target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc1a008-6c59-4437-96e9-e53d78d213d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_, y_test_ = get_test_data_and_labels(test_data_file_m,TARGETS_m[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ffe42-5491-4e24-9d38-d564e5b82a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_, y_pred_ = y_test_, clf.predict(X_test_)\n",
    "print(classification_report(y_true_, y_pred_, digits = 4, labels = [0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c6fe2-8315-47cd-8fe3-8f5e75772316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e9ba8-3ed3-4527-8ba2-063ddd754537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b9d8ed-840f-474c-bbbd-c0fce3fdcff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ff24d8-b3fb-4de7-8af5-24d0dfdcd284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3afa63-0f18-4a38-871e-8cb245ceaef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4fc89db-4b42-4aa4-87ea-87e6c0366cc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'windsound'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43617/3753918386.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwindsound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'windsound'"
     ]
    }
   ],
   "source": [
    "import windsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c1e8527-2038-4c5c-9983-bcede1ae9ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement windsound (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for windsound\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install windsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8432b7e7-290a-4043-ac4d-c1832206b9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpKernel",
   "language": "python",
   "name": "nlpkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
